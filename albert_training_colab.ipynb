{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"albert_training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1fg_2JuSxhNJF-5maUMEHvoSXt4bhp3f6","authorship_tag":"ABX9TyPfv4/M7Ig+8sdkQRWrRaJz"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjdgjGo0Wu2G","executionInfo":{"status":"ok","timestamp":1609289898560,"user_tz":-480,"elapsed":1300,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"7ccb432e-639c-42ad-ac85-5d56bf8fdfc4"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Dec 30 00:58:17 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cOaDX2nur6RL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609289902138,"user_tz":-480,"elapsed":1055,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"3466d048-f57b-4111-9c6b-f3e2e1b81d5e"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEnNgKkACYms","executionInfo":{"status":"ok","timestamp":1609289914427,"user_tz":-480,"elapsed":7801,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"a8e69433-f0c7-4d68-cd87-9f88389d37cd"},"source":["!pip3 install nltk\n","import nltk\n","nltk.download('punkt')\n","\n","!pip3 install toposort"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Collecting toposort\n","  Downloading https://files.pythonhosted.org/packages/f2/7d/55784e894ee0cde2474fb977ffd1651e74e840a9f92e1d847f7e3115d5ec/toposort-1.6-py2.py3-none-any.whl\n","Installing collected packages: toposort\n","Successfully installed toposort-1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBgZQn_u43-k"},"source":["#import os\n","#import urllib.request\n","#urllib.request.urlretrieve('https://storage.googleapis.com/albert_models/albert_base_zh.tar.gz','albert_base_zh.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yivAfdrh9DoK","executionInfo":{"status":"ok","timestamp":1609289922002,"user_tz":-480,"elapsed":1130,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"0e8c857f-edef-42c6-b3ba-feb795a47c13"},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/colab_data/packages/albert_QA_colab')\n","#sys.path=['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n","print(sys.path)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['/tensorflow-1.15.2/python3.6', '', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/colab_data/packages/albert_QA_colab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uSVWIcpxLGuL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609289938798,"user_tz":-480,"elapsed":8445,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"2d707ff0-ed0a-4b00-b1af-6484f47512fa"},"source":["# 替换 gradients.gradients 用于 recompute\n","# https://github.com/tensorpack/tensorpack/issues/654\n","# https://github.com/cybertronai/gradient-checkpointing/issues/4\n","import memory_saving_gradients\n","from tensorflow.python.ops import gradients\n","# monkey patch tf.gradients to point to our custom version, with automatic checkpoint selection\n","def gradients_memory(ys, xs, grad_ys=None, **kwargs):\n","    return memory_saving_gradients.gradients(ys, xs, grad_ys, checkpoints='collection', **kwargs)\n","gradients.__dict__[\"gradients\"] = gradients_memory \n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBPMphH6rX44","executionInfo":{"status":"ok","timestamp":1609289944837,"user_tz":-480,"elapsed":2594,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"5d465237-a36a-4257-b7b3-d8ad25fc2824"},"source":["import tensorflow.compat.v1 as tf\n","print(tf.__version__)\n","print(tf.test.is_gpu_available())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1.15.2\n","True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QDScCb3V9hJI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609289957539,"user_tz":-480,"elapsed":9237,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"c74f7390-83f8-43fe-f9a5-0d7e6528dea6"},"source":["# coding=utf-8\n","\n","import os\n","# 启用AMP, Volta以下显卡，需要设置环境变量 TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE=1\n","# 原因来自：https://devtalk.nvidia.com/default/topic/1052688/container-tensorflow/\n","#               issue-about-no-suitable-gpus-detected-when-using-mixed-precision-graph-optimizer/\n","os.environ['TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE'] = '1'\n","\n","import argparse\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","\n","# 'Please setup horovod before using multi-gpu!!!'\n","hvd = None\n","\n","from optimizations.tf_optimization import Optimizer\n","import json\n","import utils\n","from evaluate.cmrc2018_evaluate import get_eval\n","from evaluate.cmrc2018_output import write_predictions\n","import random\n","from tqdm import tqdm\n","import collections\n","from tokenizations.official_tokenization import BertTokenizer\n","from preprocess.cmrc2018_preprocess import json2features\n","\n","\n","def print_rank0(*args):\n","    if mpi_rank == 0:\n","        print(*args, flush=True)\n","\n","\n","def get_session(sess):\n","    session = sess\n","    while type(session).__name__ != 'Session':\n","        session = session._sess\n","    return session\n","\n","\n","def data_generator(data, n_batch, shuffle=False, drop_last=False):\n","    steps_per_epoch = len(data) // n_batch\n","    if len(data) % n_batch != 0 and not drop_last:\n","        steps_per_epoch += 1\n","    data_set = dict()\n","    for k in data[0]:\n","        data_set[k] = np.array([data_[k] for data_ in data])\n","    index_all = np.arange(len(data))\n","\n","    while True:\n","        if shuffle:\n","            random.shuffle(index_all)\n","        for i in range(steps_per_epoch):\n","            yield {k: data_set[k][index_all[i * n_batch:(i + 1) * n_batch]] for k in data_set}\n","\n","def str2bool(v):\n","    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n","        return True\n","    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n","        return False\n","    else:\n","        raise argparse.ArgumentTypeError('Unsupported value encountered.')\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/optimizations/tf_optimization.py:110: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDfdKggi95Wo","outputId":"e7788b20-32d5-4921-e10f-7188502cceb2"},"source":["tf.reset_default_graph()\n","\n","parser = argparse.ArgumentParser()\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","parser.add_argument('--model', type=str, default='') # albert, albert_zh, albert_google\n","parser.add_argument('--gpu_ids', type=str, default='0')\n","\n","# training parameter\n","parser.add_argument('--train_epochs', type=int, default=2)\n","parser.add_argument('--n_batch', type=int, default=32)\n","parser.add_argument('--lr', type=float, default=3e-5)\n","parser.add_argument('--dropout', type=float, default=0.1)\n","parser.add_argument('--clip_norm', type=float, default=1.0)\n","parser.add_argument('--warmup_rate', type=float, default=0.1)\n","parser.add_argument('--loss_count', type=int, default=1000)\n","parser.add_argument('--seed', type=list, default=[123])\n","parser.add_argument('--float16', type=str2bool, nargs='?', const=True, default='True')  # only sm >= 7.0 (tensorcores)\n","parser.add_argument('--max_ans_length', type=int, default=50)\n","parser.add_argument('--log_interval', type=int, default=30)  # show the average loss per 30 steps args.\n","parser.add_argument('--n_best', type=int, default=20)\n","parser.add_argument('--eval_epochs', type=float, default=0.5)\n","parser.add_argument('--save_best', type=str2bool, nargs='?', const=True, default='True')\n","parser.add_argument('--vocab_size', type=int, default=21128)\n","parser.add_argument('--max_seq_length', type=int, default=512)\n","\n","# data dir\n","parser.add_argument('--train_dir', type=str, default='/content/outputs/cmrc2018/data/train_features_albert.json')\n","parser.add_argument('--dev_dir1', type=str, default='/content/outputs/cmrc2018/data/dev_examples_albert.json')\n","parser.add_argument('--dev_dir2', type=str, default='/content/outputs/cmrc2018/data/dev_features_albert.json')\n","parser.add_argument('--train_file', type=str, default='/content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_train.json')\n","parser.add_argument('--dev_file', type=str, default='/content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_trial.json')\n","parser.add_argument('--vocab_file', type=str, default='')\n","parser.add_argument('--bert_config_file', type=str, default='')\n","parser.add_argument('--init_restore_dir', type=str, default='')\n","parser.add_argument('--checkpoint_dir', type=str, default='')\n","parser.add_argument('--setting_file', type=str, default='setting.txt')\n","parser.add_argument('--log_file', type=str, default='log.txt')\n","\n","# use some global vars for convenience\n","args = parser.parse_args(args=[])\n","\n","# 训练参数\n","args.model='bert_google'\n","args.float16=True\n","args.train_epochs=3\n","args.n_batch=96\n","args.lr=3e-5\n","args.seed=[123,456,789]\n","\n","# 设置模型相关参数，如果未设置的话\n","if args.model == 'albert_zh':\n","    from models.albert_zh_modeling import AlbertModelMRC, BertConfig as AlbertConfig\n","    #model_name = 'albert_base_zh_36k'\n","    model_name = 'albert_large_zh'\n","    model_path = '/content/drive/MyDrive/colab_data/models/%s/'%model_name\n","    args.vocab_file = args.vocab_file if args.vocab_file else model_path+'vocab.txt'\n","    args.bert_config_file = args.bert_config_file if args.bert_config_file else model_path+'albert_config_large.json'\n","    args.init_restore_dir = args.init_restore_dir if args.init_restore_dir else model_path+'albert_model.ckpt'\n","elif args.model in ['albert', 'albert_google']:\n","    if args.model == 'albert':  \n","        from models.albert_modeling import AlbertModelMRC, AlbertConfig\n","    else:\n","        from models.albert_google_modeling import AlbertModelMRC, AlbertConfig\n","    model_name = 'albert_base'\n","    model_path = '/content/drive/MyDrive/colab_data/models/%s/'%model_name\n","    args.vocab_file = args.vocab_file if args.vocab_file else model_path+'vocab_chinese.txt'\n","    args.bert_config_file = args.bert_config_file if args.bert_config_file else model_path+'albert_config.json'\n","    args.init_restore_dir = args.init_restore_dir if args.init_restore_dir else model_path+'model.ckpt-best'\n","elif args.model == 'bert_google':\n","    from models.bert_google_modeling import BertModelMRC as AlbertModelMRC, BertConfig as AlbertConfig\n","    model_name = 'chinese_L-12_H-768_A-12'\n","    model_path = '/content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/%s/'%model_name\n","    args.vocab_file = args.vocab_file if args.vocab_file else model_path+'vocab.txt'\n","    args.bert_config_file = args.bert_config_file if args.bert_config_file else model_path+'bert_config.json'\n","    args.init_restore_dir = args.init_restore_dir if args.init_restore_dir else model_path+'bert_model.ckpt'\n","else:\n","    print(\"UNKNOWN model name: [\", args.model, \"]. Available mode: ablert, albert_zh, albert_google.\")\n","    sys.exit(0)\n","\n","args.checkpoint_dir = args.checkpoint_dir if args.checkpoint_dir else '/content/drive/MyDrive/colab_data/outputs/cmrc2018/%s'%model_name\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_ids\n","n_gpu = len(args.gpu_ids.split(','))\n","hvd = None\n","mpi_size = 1\n","mpi_rank = 0\n","training_hooks = None\n","print('GPU NUM', n_gpu)\n","\n","args.checkpoint_dir += ('/epoch{}_batch{}_lr{}_warmup{}_anslen{}_tf/'\n","                        .format(args.train_epochs, args.n_batch, args.lr, args.warmup_rate, args.max_ans_length))\n","args = utils.check_args(args, mpi_rank)\n","print_rank0('######## generating data ########')\n","\n","if mpi_rank == 0:\n","    tokenizer = BertTokenizer(vocab_file=args.vocab_file, do_lower_case=True)\n","    # assert args.vocab_size == len(tokenizer.vocab)\n","    if not os.path.exists(args.train_dir):\n","        json2features(args.train_file, [args.train_dir.replace('_features_', '_examples_'), args.train_dir], \n","            tokenizer, is_training=True, max_seq_length=args.max_seq_length)\n","\n","    if not os.path.exists(args.dev_dir1) or not os.path.exists(args.dev_dir2):\n","        json2features(args.dev_file, [args.dev_dir1, args.dev_dir2], \n","            tokenizer, is_training=False, max_seq_length=args.max_seq_length)\n","\n","train_data = json.load(open(args.train_dir, 'r'))\n","dev_examples = json.load(open(args.dev_dir1, 'r'))\n","dev_data = json.load(open(args.dev_dir2, 'r'))\n","\n","if mpi_rank == 0:\n","    if os.path.exists(args.log_file):\n","        os.remove(args.log_file)\n","\n","steps_per_epoch = len(train_data) // args.n_batch\n","eval_steps = int(steps_per_epoch * args.eval_epochs)\n","dev_steps_per_epoch = len(dev_data) // (args.n_batch * n_gpu)\n","if len(train_data) % args.n_batch != 0:\n","    steps_per_epoch += 1\n","if len(dev_data) % (args.n_batch * n_gpu) != 0:\n","    dev_steps_per_epoch += 1\n","total_steps = steps_per_epoch * args.train_epochs\n","warmup_iters = int(args.warmup_rate * total_steps)\n","\n","print_rank0('steps per epoch:', steps_per_epoch)\n","print_rank0('total steps:', total_steps)\n","print_rank0('warmup steps:', warmup_iters)\n","\n","F1s = []\n","EMs = []\n","best_f1_em = 0\n","with tf.device(\"/gpu:0\"):\n","    input_ids = tf.placeholder(tf.int32, shape=[None, args.max_seq_length], name='input_ids')\n","    input_masks = tf.placeholder(tf.float32, shape=[None, args.max_seq_length], name='input_masks')\n","    segment_ids = tf.placeholder(tf.int32, shape=[None, args.max_seq_length], name='segment_ids')\n","    start_positions = tf.placeholder(tf.int32, shape=[None, ], name='start_positions')\n","    end_positions = tf.placeholder(tf.int32, shape=[None, ], name='end_positions')\n","\n","# build the models for training and testing/validation\n","print_rank0('######## init model ########')\n","bert_config = AlbertConfig.from_json_file(args.bert_config_file)\n","train_model = AlbertModelMRC(config=bert_config,\n","                              is_training=True,\n","                              input_ids=input_ids,\n","                              input_mask=input_masks,\n","                              token_type_ids=segment_ids,\n","                              start_positions=start_positions,\n","                              end_positions=end_positions,\n","                              use_float16=args.float16)\n","\n","eval_model = AlbertModelMRC(config=bert_config,\n","                            is_training=False,\n","                            input_ids=input_ids,\n","                            input_mask=input_masks,\n","                            token_type_ids=segment_ids,\n","                            use_float16=args.float16)\n","\n","optimization = Optimizer(loss=train_model.train_loss,\n","                          init_lr=args.lr,\n","                          num_train_steps=total_steps,\n","                          num_warmup_steps=warmup_iters,\n","                          hvd=hvd,\n","                          use_fp16=args.float16,\n","                          loss_count=args.loss_count,\n","                          clip_norm=args.clip_norm)\n","\n","if mpi_rank == 0:\n","    saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=1)\n","else:\n","    saver = None\n","\n","\n","# 开始训练\n","for seed_ in args.seed:\n","    best_f1, best_em = 0, 0\n","    if mpi_rank == 0:\n","        with open(args.log_file, 'a') as aw:\n","            aw.write('===================================' +\n","                      'SEED:' + str(seed_)\n","                      + '===================================' + '\\n')\n","    print_rank0('SEED:', seed_)\n","    # random seed\n","    np.random.seed(seed_)\n","    random.seed(seed_)\n","    tf.set_random_seed(seed_)\n","\n","    train_gen = data_generator(train_data, args.n_batch, shuffle=True, drop_last=False)\n","    dev_gen = data_generator(dev_data, args.n_batch * n_gpu, shuffle=False, drop_last=False)\n","\n","    config = tf.ConfigProto()\n","    config.gpu_options.visible_device_list = str(mpi_rank)\n","    config.allow_soft_placement = True\n","    config.gpu_options.allow_growth = True\n","\n","    utils.show_all_variables(rank=mpi_rank)\n","    utils.init_from_checkpoint(args.init_restore_dir, rank=mpi_rank)\n","    RawResult = collections.namedtuple(\"RawResult\",\n","                                        [\"unique_id\", \"start_logits\", \"end_logits\"])\n","\n","    with tf.train.MonitoredTrainingSession(checkpoint_dir=None,\n","                                            hooks=training_hooks,\n","                                            config=config) as sess:\n","        old_global_steps = sess.run(optimization.global_step)\n","        for i in range(args.train_epochs):\n","            print_rank0('Starting epoch %d' % (i + 1))\n","            total_loss = 0\n","            iteration = 0\n","            with tqdm(total=steps_per_epoch, desc='Epoch %d' % (i + 1),\n","                      disable=False if mpi_rank == 0 else True) as pbar:\n","                while iteration < steps_per_epoch:\n","                    batch_data = next(train_gen)\n","                    feed_data = {input_ids: batch_data['input_ids'],\n","                                  input_masks: batch_data['input_mask'],\n","                                  segment_ids: batch_data['segment_ids'],\n","                                  start_positions: batch_data['start_position'],\n","                                  end_positions: batch_data['end_position']}\n","                    loss, _, global_steps = sess.run(\n","                        [train_model.train_loss, optimization.train_op, optimization.global_step],\n","                        feed_dict=feed_data)\n","                    if global_steps > old_global_steps:\n","                        old_global_steps = global_steps\n","                        total_loss += loss\n","                        pbar.set_postfix({'loss': '{0:1.5f}'.format(total_loss / (iteration + 1e-5))})\n","                        pbar.update(1)\n","                        iteration += 1\n","                    else:\n","                        print_rank0('NAN loss in', iteration, ', Loss scale reduced', )\n","\n","                    if global_steps % eval_steps == 0 and global_steps > 1:\n","                        print_rank0('Evaluating...')\n","                        all_results = []\n","                        for i_step in tqdm(range(dev_steps_per_epoch),\n","                                            disable=False if mpi_rank == 0 else True):\n","                            batch_data = next(dev_gen)\n","                            feed_data = {input_ids: batch_data['input_ids'],\n","                                          input_masks: batch_data['input_mask'],\n","                                          segment_ids: batch_data['segment_ids']}\n","                            batch_start_logits, batch_end_logits = sess.run(\n","                                [eval_model.start_logits, eval_model.end_logits],\n","                                feed_dict=feed_data)\n","                            for j in range(len(batch_data['unique_id'])):\n","                                start_logits = batch_start_logits[j]\n","                                end_logits = batch_end_logits[j]\n","                                unique_id = batch_data['unique_id'][j]\n","                                all_results.append(RawResult(unique_id=unique_id,\n","                                                              start_logits=start_logits,\n","                                                              end_logits=end_logits))\n","                        if mpi_rank == 0:\n","                            output_prediction_file = os.path.join(args.checkpoint_dir,\n","                                                                  'prediction_epoch' + str(i) + '.json')\n","                            output_nbest_file = os.path.join(args.checkpoint_dir, 'nbest_epoch' + str(i) + '.json')\n","\n","                            write_predictions(dev_examples, dev_data, all_results,\n","                                              n_best_size=args.n_best, max_answer_length=args.max_ans_length,\n","                                              do_lower_case=True, output_prediction_file=output_prediction_file,\n","                                              output_nbest_file=output_nbest_file)\n","                            tmp_result = get_eval(args.dev_file, output_prediction_file)\n","                            tmp_result['STEP'] = global_steps\n","                            print_rank0(tmp_result)\n","                            with open(args.log_file, 'a') as aw:\n","                                aw.write(json.dumps(str(tmp_result)) + '\\n')\n","\n","                            if float(tmp_result['F1']) > best_f1:\n","                                best_f1 = float(tmp_result['F1'])\n","                            if float(tmp_result['EM']) > best_em:\n","                                best_em = float(tmp_result['EM'])\n","\n","                            if float(tmp_result['F1']) + float(tmp_result['EM']) > best_f1_em:\n","                                best_f1_em = float(tmp_result['F1']) + float(tmp_result['EM'])\n","                                scores = {'F1': float(tmp_result['F1']), 'EM': float(tmp_result['EM'])}\n","                                save_prex = \"checkpoint_score\"\n","                                for k in scores:\n","                                    save_prex += ('_' + k + '-' + str(scores[k])[:6])\n","                                save_prex += '.ckpt'\n","                                saver.save(get_session(sess),\n","                                            save_path=os.path.join(args.checkpoint_dir, save_prex))\n","\n","    F1s.append(best_f1)\n","    EMs.append(best_em)\n","\n","if mpi_rank == 0:\n","    print('Mean F1:', np.mean(F1s), 'Mean EM:', np.mean(EMs))\n","    print('Best F1:', np.max(F1s), 'Best EM:', np.max(EMs))\n","    with open(args.log_file, 'a') as aw:\n","        aw.write('Mean(Best) F1:{}({})\\n'.format(np.mean(F1s), np.max(F1s)))\n","        aw.write('Mean(Best) EM:{}({})\\n'.format(np.mean(EMs), np.max(EMs)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU NUM 1\n","------------ Options -------------\n","model: bert_google\n","gpu_ids: 0\n","train_epochs: 3\n","n_batch: 96\n","lr: 3e-05\n","dropout: 0.1\n","clip_norm: 1.0\n","warmup_rate: 0.1\n","loss_count: 1000\n","seed: [123, 456, 789]\n","float16: True\n","max_ans_length: 50\n","log_interval: 30\n","n_best: 20\n","eval_epochs: 0.5\n","save_best: True\n","vocab_size: 21128\n","max_seq_length: 512\n","train_dir: /content/outputs/cmrc2018/data/train_features_albert.json\n","dev_dir1: /content/outputs/cmrc2018/data/dev_examples_albert.json\n","dev_dir2: /content/outputs/cmrc2018/data/dev_features_albert.json\n","train_file: /content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_train.json\n","dev_file: /content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_trial.json\n","vocab_file: /content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/vocab.txt\n","bert_config_file: /content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\n","init_restore_dir: /content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_model.ckpt\n","checkpoint_dir: /content/drive/MyDrive/colab_data/outputs/cmrc2018/chinese_L-12_H-768_A-12/epoch3_batch96_lr3e-05_warmup0.1_anslen50_tf/\n","setting_file: /content/drive/MyDrive/colab_data/outputs/cmrc2018/chinese_L-12_H-768_A-12/epoch3_batch96_lr3e-05_warmup0.1_anslen50_tf/setting.txt\n","log_file: /content/drive/MyDrive/colab_data/outputs/cmrc2018/chinese_L-12_H-768_A-12/epoch3_batch96_lr3e-05_warmup0.1_anslen50_tf/log.txt\n","------------ End -------------\n","######## generating data ########\n","steps per epoch: 236\n","total steps: 708\n","warmup steps: 70\n","######## init model ########\n","ts_all 1=  1610\n","checkpoints =  24\n","SEED: 123\n","---------\n","Variables: name (type shape) [size]\n","---------\n","bert/embeddings/word_embeddings:0 (float32_ref 21128x768) [16226304, bytes: 64905216]\n","bert/embeddings/token_type_embeddings:0 (float32_ref 2x768) [1536, bytes: 6144]\n","bert/embeddings/position_embeddings:0 (float32_ref 512x768) [393216, bytes: 1572864]\n","bert/embeddings/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/embeddings/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_0/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_0/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_0/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_0/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_0/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_0/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_0/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_0/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_1/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_1/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_1/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_1/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_1/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_1/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_1/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_1/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_2/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_2/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_2/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_2/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_2/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_2/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_2/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_2/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_3/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_3/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_3/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_3/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_3/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_3/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_3/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_3/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_4/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_4/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_4/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_4/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_4/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_4/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_4/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_4/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_5/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_5/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_5/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_5/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_5/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_5/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_5/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_5/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_6/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_6/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_6/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_6/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_6/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_6/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_6/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_6/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_7/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_7/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_7/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_7/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_7/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_7/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_7/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_7/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_8/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_8/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_8/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_8/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_8/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_8/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_8/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_8/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_9/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_9/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_9/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_9/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_9/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_9/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_9/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_9/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_10/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_10/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_10/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_10/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_10/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_10/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_10/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_10/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/attention/self/query/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_11/attention/self/query/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/attention/self/key/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_11/attention/self/key/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/attention/self/value/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_11/attention/self/value/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/attention/output/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/encoder/layer_11/attention/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/attention/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/attention/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/intermediate/dense/kernel:0 (float32_ref 768x3072) [2359296, bytes: 9437184]\n","bert/encoder/layer_11/intermediate/dense/bias:0 (float32_ref 3072) [3072, bytes: 12288]\n","bert/encoder/layer_11/output/dense/kernel:0 (float32_ref 3072x768) [2359296, bytes: 9437184]\n","bert/encoder/layer_11/output/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/output/LayerNorm/beta:0 (float32_ref 768) [768, bytes: 3072]\n","bert/encoder/layer_11/output/LayerNorm/gamma:0 (float32_ref 768) [768, bytes: 3072]\n","bert/pooler/dense/kernel:0 (float32_ref 768x768) [589824, bytes: 2359296]\n","bert/pooler/dense/bias:0 (float32_ref 768) [768, bytes: 3072]\n","finetune_mrc/qa_outputs/kernel:0 (float32_ref 768x2) [1536, bytes: 6144]\n","finetune_mrc/qa_outputs/bias:0 (float32_ref 2) [2, bytes: 8]\n","Total size of variables: 102269186\n","Total bytes of variables: 409076744\n","Loading weights success: bert/embeddings/LayerNorm/beta\n","Loading weights success: bert/embeddings/LayerNorm/gamma\n","Loading weights success: bert/embeddings/position_embeddings\n","Loading weights success: bert/embeddings/token_type_embeddings\n","Loading weights success: bert/embeddings/word_embeddings\n","Loading weights success: bert/encoder/layer_0/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_0/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_0/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_0/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_0/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_0/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_0/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_0/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_0/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_0/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_0/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_0/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_0/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_0/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_0/output/dense/bias\n","Loading weights success: bert/encoder/layer_0/output/dense/kernel\n","Loading weights success: bert/encoder/layer_1/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_1/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_1/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_1/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_1/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_1/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_1/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_1/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_1/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_1/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_1/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_1/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_1/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_1/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_1/output/dense/bias\n","Loading weights success: bert/encoder/layer_1/output/dense/kernel\n","Loading weights success: bert/encoder/layer_10/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_10/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_10/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_10/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_10/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_10/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_10/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_10/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_10/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_10/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_10/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_10/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_10/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_10/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_10/output/dense/bias\n","Loading weights success: bert/encoder/layer_10/output/dense/kernel\n","Loading weights success: bert/encoder/layer_11/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_11/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_11/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_11/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_11/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_11/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_11/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_11/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_11/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_11/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_11/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_11/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_11/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_11/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_11/output/dense/bias\n","Loading weights success: bert/encoder/layer_11/output/dense/kernel\n","Loading weights success: bert/encoder/layer_2/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_2/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_2/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_2/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_2/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_2/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_2/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_2/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_2/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_2/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_2/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_2/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_2/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_2/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_2/output/dense/bias\n","Loading weights success: bert/encoder/layer_2/output/dense/kernel\n","Loading weights success: bert/encoder/layer_3/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_3/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_3/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_3/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_3/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_3/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_3/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_3/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_3/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_3/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_3/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_3/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_3/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_3/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_3/output/dense/bias\n","Loading weights success: bert/encoder/layer_3/output/dense/kernel\n","Loading weights success: bert/encoder/layer_4/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_4/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_4/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_4/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_4/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_4/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_4/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_4/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_4/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_4/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_4/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_4/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_4/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_4/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_4/output/dense/bias\n","Loading weights success: bert/encoder/layer_4/output/dense/kernel\n","Loading weights success: bert/encoder/layer_5/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_5/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_5/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_5/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_5/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_5/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_5/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_5/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_5/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_5/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_5/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_5/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_5/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_5/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_5/output/dense/bias\n","Loading weights success: bert/encoder/layer_5/output/dense/kernel\n","Loading weights success: bert/encoder/layer_6/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_6/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_6/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_6/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_6/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_6/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_6/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_6/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_6/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_6/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_6/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_6/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_6/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_6/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_6/output/dense/bias\n","Loading weights success: bert/encoder/layer_6/output/dense/kernel\n","Loading weights success: bert/encoder/layer_7/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_7/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_7/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_7/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_7/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_7/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_7/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_7/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_7/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_7/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_7/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_7/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_7/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_7/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_7/output/dense/bias\n","Loading weights success: bert/encoder/layer_7/output/dense/kernel\n","Loading weights success: bert/encoder/layer_8/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_8/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_8/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_8/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_8/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_8/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_8/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_8/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_8/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_8/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_8/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_8/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_8/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_8/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_8/output/dense/bias\n","Loading weights success: bert/encoder/layer_8/output/dense/kernel\n","Loading weights success: bert/encoder/layer_9/attention/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_9/attention/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_9/attention/output/dense/bias\n","Loading weights success: bert/encoder/layer_9/attention/output/dense/kernel\n","Loading weights success: bert/encoder/layer_9/attention/self/key/bias\n","Loading weights success: bert/encoder/layer_9/attention/self/key/kernel\n","Loading weights success: bert/encoder/layer_9/attention/self/query/bias\n","Loading weights success: bert/encoder/layer_9/attention/self/query/kernel\n","Loading weights success: bert/encoder/layer_9/attention/self/value/bias\n","Loading weights success: bert/encoder/layer_9/attention/self/value/kernel\n","Loading weights success: bert/encoder/layer_9/intermediate/dense/bias\n","Loading weights success: bert/encoder/layer_9/intermediate/dense/kernel\n","Loading weights success: bert/encoder/layer_9/output/LayerNorm/beta\n","Loading weights success: bert/encoder/layer_9/output/LayerNorm/gamma\n","Loading weights success: bert/encoder/layer_9/output/dense/bias\n","Loading weights success: bert/encoder/layer_9/output/dense/kernel\n","Loading weights success: bert/pooler/dense/bias\n","Loading weights success: bert/pooler/dense/kernel\n","New parameters: {'finetune_mrc/qa_outputs/bias', 'finetune_mrc/qa_outputs/kernel'}\n","Unused parameters {'cls/predictions/transform/dense/kernel', 'cls/predictions/output_bias', 'cls/predictions/transform/dense/bias', 'cls/seq_relationship/output_bias', 'cls/predictions/transform/LayerNorm/gamma', 'cls/predictions/transform/LayerNorm/beta', 'cls/seq_relationship/output_weights'}\n","Starting epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch 1:   0%|          | 0/236 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["NAN loss in 0 , Loss scale reduced\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1:   8%|▊         | 20/236 [04:01<39:36, 11.00s/it, loss=5.33911]"],"name":"stderr"},{"output_type":"stream","text":["NAN loss in 20 , Loss scale reduced\n","NAN loss in 20 , Loss scale reduced\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1:  50%|████▉     | 117/236 [22:08<21:45, 10.97s/it, loss=2.43413]"],"name":"stderr"},{"output_type":"stream","text":["Evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/19 [00:03<01:03,  3.53s/it]\u001b[A\n"," 11%|█         | 2/19 [00:06<00:55,  3.24s/it]\u001b[A\n"," 16%|█▌        | 3/19 [00:08<00:48,  3.03s/it]\u001b[A\n"," 21%|██        | 4/19 [00:11<00:43,  2.89s/it]\u001b[A\n"," 26%|██▋       | 5/19 [00:13<00:39,  2.79s/it]\u001b[A\n"," 32%|███▏      | 6/19 [00:16<00:35,  2.71s/it]\u001b[A\n"," 37%|███▋      | 7/19 [00:18<00:31,  2.66s/it]\u001b[A\n"," 42%|████▏     | 8/19 [00:21<00:28,  2.63s/it]\u001b[A\n"," 47%|████▋     | 9/19 [00:23<00:26,  2.61s/it]\u001b[A\n"," 53%|█████▎    | 10/19 [00:26<00:23,  2.59s/it]\u001b[A\n"," 58%|█████▊    | 11/19 [00:29<00:20,  2.58s/it]\u001b[A\n"," 63%|██████▎   | 12/19 [00:31<00:17,  2.57s/it]\u001b[A\n"," 68%|██████▊   | 13/19 [00:34<00:15,  2.56s/it]\u001b[A\n"," 74%|███████▎  | 14/19 [00:36<00:12,  2.56s/it]\u001b[A\n"," 79%|███████▉  | 15/19 [00:39<00:10,  2.56s/it]\u001b[A\n"," 84%|████████▍ | 16/19 [00:41<00:07,  2.56s/it]\u001b[A\n"," 89%|████████▉ | 17/19 [00:44<00:05,  2.56s/it]\u001b[A\n"," 95%|█████████▍| 18/19 [00:46<00:02,  2.56s/it]\u001b[A\n","100%|██████████| 19/19 [00:47<00:00,  2.49s/it]\n","\n","  0%|          | 0/1002 [00:00<?, ?it/s]\u001b[A\n","  2%|▏         | 24/1002 [00:00<00:04, 232.01it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Writing predictions to: /content/drive/MyDrive/colab_data/outputs/cmrc2018/chinese_L-12_H-768_A-12/epoch3_batch96_lr3e-05_warmup0.1_anslen50_tf/prediction_epoch0.json\n","Writing nbest to: /content/drive/MyDrive/colab_data/outputs/cmrc2018/chinese_L-12_H-768_A-12/epoch3_batch96_lr3e-05_warmup0.1_anslen50_tf/nbest_epoch0.json\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  5%|▍         | 50/1002 [00:00<00:03, 238.89it/s]\u001b[A\n","  7%|▋         | 75/1002 [00:00<00:03, 241.54it/s]\u001b[A\n"," 10%|▉         | 97/1002 [00:00<00:03, 233.37it/s]\u001b[A\n"," 12%|█▏        | 121/1002 [00:00<00:03, 233.17it/s]\u001b[A\n"," 15%|█▍        | 149/1002 [00:00<00:03, 244.58it/s]\u001b[A\n"," 17%|█▋        | 174/1002 [00:00<00:03, 244.02it/s]\u001b[A\n"," 20%|█▉        | 197/1002 [00:00<00:03, 237.33it/s]\u001b[A\n"," 22%|██▏       | 220/1002 [00:00<00:03, 230.33it/s]\u001b[A\n"," 24%|██▍       | 244/1002 [00:01<00:03, 232.09it/s]\u001b[A\n"," 27%|██▋       | 267/1002 [00:01<00:03, 219.57it/s]\u001b[A\n"," 29%|██▉       | 289/1002 [00:01<00:03, 215.19it/s]\u001b[A\n"," 31%|███       | 311/1002 [00:01<00:03, 208.23it/s]\u001b[A\n"," 33%|███▎      | 335/1002 [00:01<00:03, 216.42it/s]\u001b[A\n"," 36%|███▌      | 357/1002 [00:01<00:03, 213.20it/s]\u001b[A\n"," 38%|███▊      | 379/1002 [00:01<00:02, 214.18it/s]\u001b[A\n"," 40%|████      | 402/1002 [00:01<00:02, 217.79it/s]\u001b[A\n"," 43%|████▎     | 427/1002 [00:01<00:02, 226.31it/s]\u001b[A\n"," 45%|████▌     | 452/1002 [00:01<00:02, 231.24it/s]\u001b[A\n"," 48%|████▊     | 476/1002 [00:02<00:02, 226.76it/s]\u001b[A\n"," 50%|█████     | 501/1002 [00:02<00:02, 230.50it/s]\u001b[A\n"," 53%|█████▎    | 527/1002 [00:02<00:01, 237.92it/s]\u001b[A\n"," 55%|█████▍    | 551/1002 [00:02<00:01, 235.50it/s]\u001b[A\n"," 58%|█████▊    | 580/1002 [00:02<00:01, 246.99it/s]\u001b[A\n"," 60%|██████    | 605/1002 [00:02<00:01, 241.37it/s]\u001b[A\n"," 63%|██████▎   | 630/1002 [00:02<00:01, 243.42it/s]\u001b[A\n"," 65%|██████▌   | 655/1002 [00:02<00:01, 243.61it/s]\u001b[A\n"," 68%|██████▊   | 680/1002 [00:02<00:01, 244.35it/s]\u001b[A\n"," 70%|███████   | 705/1002 [00:03<00:01, 242.77it/s]\u001b[A\n"," 73%|███████▎  | 730/1002 [00:03<00:01, 243.61it/s]\u001b[A\n"," 76%|███████▌  | 758/1002 [00:03<00:00, 252.84it/s]\u001b[A\n"," 78%|███████▊  | 784/1002 [00:03<00:00, 250.13it/s]\u001b[A\n"," 81%|████████  | 810/1002 [00:03<00:00, 238.74it/s]\u001b[A\n"," 84%|████████▎ | 837/1002 [00:03<00:00, 246.06it/s]\u001b[A\n"," 86%|████████▌ | 862/1002 [00:03<00:00, 231.00it/s]\u001b[A\n"," 89%|████████▊ | 888/1002 [00:03<00:00, 236.96it/s]\u001b[A\n"," 91%|█████████ | 912/1002 [00:03<00:00, 236.12it/s]\u001b[A\n"," 93%|█████████▎| 936/1002 [00:03<00:00, 236.53it/s]\u001b[A\n"," 96%|█████████▌| 960/1002 [00:04<00:00, 233.07it/s]\u001b[A\n","100%|██████████| 1002/1002 [00:04<00:00, 235.74it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["OrderedDict([('AVERAGE', '47.316'), ('F1', '66.487'), ('EM', '28.144'), ('TOTAL', 1002), ('SKIP', 0), ('STEP', 117)])\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1:  58%|█████▊    | 137/236 [26:43<18:08, 10.99s/it, loss=2.26958]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hIBCICZFTxGL"},"source":["#!tar cvfJ /content/drive/MyDrive/colab_data/echo4.xv /content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf"],"execution_count":null,"outputs":[]}]}