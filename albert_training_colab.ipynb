{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"albert_training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1fg_2JuSxhNJF-5maUMEHvoSXt4bhp3f6","authorship_tag":"ABX9TyNaU4dvGvYUJMMtSwHpCbkt"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjdgjGo0Wu2G","executionInfo":{"status":"ok","timestamp":1609134850722,"user_tz":-480,"elapsed":1528,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"24d3d901-1559-4c8c-d075-4aa200f8f5fd"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mon Dec 28 05:54:10 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOaDX2nur6RL","executionInfo":{"status":"ok","timestamp":1609134855953,"user_tz":-480,"elapsed":1446,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"1dc01f23-ae7a-4225-e11f-dca43b51db06"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nV_yAoBd6Zxp","executionInfo":{"status":"ok","timestamp":1609134884485,"user_tz":-480,"elapsed":7845,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"cc3d895f-4a54-4a6a-9622-cbb8c9cc90f2"},"source":["import tensorflow.compat.v1 as tf\n","print(tf.__version__)\n","print(tf.test.is_gpu_available())\n","import keras\n","print(keras.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1.15.2\n","True\n","2.3.1\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEnNgKkACYms","executionInfo":{"status":"ok","timestamp":1609134902924,"user_tz":-480,"elapsed":5680,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"ead9a34b-6577-4c66-8734-a16c8bef91b6"},"source":["!pip3 install nltk\n","import nltk\n","nltk.download('punkt')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBPMphH6rX44","executionInfo":{"status":"ok","timestamp":1609134915740,"user_tz":-480,"elapsed":858,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"641dbef5-42ed-4592-90ea-d5284114b62c"},"source":["import tensorflow.compat.v1 as tf\n","print(tf.__version__)\n","print(tf.test.is_gpu_available())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1.15.2\n","True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBgZQn_u43-k"},"source":["#import os\n","#import urllib.request\n","#urllib.request.urlretrieve('https://storage.googleapis.com/albert_models/albert_base_zh.tar.gz','albert_base_zh.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yivAfdrh9DoK","executionInfo":{"status":"ok","timestamp":1609134985575,"user_tz":-480,"elapsed":1840,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"49a8617b-3ca0-4af9-d24b-b52f53e9046e"},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/colab_data/packages/albert_QA_colab')\n","#sys.path=['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n","print(sys.path)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["['/tensorflow-1.15.2/python3.6', '', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/colab_data/packages/albert_QA_colab']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDScCb3V9hJI","executionInfo":{"status":"ok","timestamp":1609135000530,"user_tz":-480,"elapsed":7155,"user":{"displayName":"Tao Guan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4-6vJCQVkP7tPscmwH-TCw9oP8Z0062aElcseQA=s64","userId":"14923390469277448374"}},"outputId":"1515b697-1c21-4666-b456-bffaf953ec31"},"source":["# coding=utf-8\n","\n","import os\n","# 启用AMP, Volta以下显卡，需要设置环境变量 TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE=1\n","# 原因来自：https://devtalk.nvidia.com/default/topic/1052688/container-tensorflow/\n","#               issue-about-no-suitable-gpus-detected-when-using-mixed-precision-graph-optimizer/\n","os.environ['TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE'] = '1'\n","\n","import argparse\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","\n","# 'Please setup horovod before using multi-gpu!!!'\n","hvd = None\n","\n","from optimizations.tf_optimization import Optimizer\n","import json\n","import utils\n","from evaluate.cmrc2018_evaluate import get_eval\n","from evaluate.cmrc2018_output import write_predictions\n","import random\n","from tqdm import tqdm\n","import collections\n","from tokenizations.official_tokenization import BertTokenizer\n","from preprocess.cmrc2018_preprocess import json2features\n","\n","\n","def print_rank0(*args):\n","    if mpi_rank == 0:\n","        print(*args, flush=True)\n","\n","\n","def get_session(sess):\n","    session = sess\n","    while type(session).__name__ != 'Session':\n","        session = session._sess\n","    return session\n","\n","\n","def data_generator(data, n_batch, shuffle=False, drop_last=False):\n","    steps_per_epoch = len(data) // n_batch\n","    if len(data) % n_batch != 0 and not drop_last:\n","        steps_per_epoch += 1\n","    data_set = dict()\n","    for k in data[0]:\n","        data_set[k] = np.array([data_[k] for data_ in data])\n","    index_all = np.arange(len(data))\n","\n","    while True:\n","        if shuffle:\n","            random.shuffle(index_all)\n","        for i in range(steps_per_epoch):\n","            yield {k: data_set[k][index_all[i * n_batch:(i + 1) * n_batch]] for k in data_set}\n","\n","def str2bool(v):\n","    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n","        return True\n","    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n","        return False\n","    else:\n","        raise argparse.ArgumentTypeError('Unsupported value encountered.')\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/MyDrive/colab_data/packages/albert_QA_colab/optimizations/tf_optimization.py:110: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"XDfdKggi95Wo","outputId":"1a27afe1-6e94-4908-8479-0ae15a87e56a"},"source":["tf.reset_default_graph()\n","\n","parser = argparse.ArgumentParser()\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","parser.add_argument('--model', type=str, default='') # albert, albert_zh, albert_google\n","parser.add_argument('--gpu_ids', type=str, default='0')\n","\n","# training parameter\n","parser.add_argument('--train_epochs', type=int, default=2)\n","parser.add_argument('--n_batch', type=int, default=32)\n","parser.add_argument('--lr', type=float, default=3e-5)\n","parser.add_argument('--dropout', type=float, default=0.1)\n","parser.add_argument('--clip_norm', type=float, default=1.0)\n","parser.add_argument('--warmup_rate', type=float, default=0.1)\n","parser.add_argument('--loss_count', type=int, default=1000)\n","parser.add_argument('--seed', type=list, default=[123])\n","parser.add_argument('--float16', type=str2bool, nargs='?', const=True, default='True')  # only sm >= 7.0 (tensorcores)\n","parser.add_argument('--max_ans_length', type=int, default=50)\n","parser.add_argument('--log_interval', type=int, default=30)  # show the average loss per 30 steps args.\n","parser.add_argument('--n_best', type=int, default=20)\n","parser.add_argument('--eval_epochs', type=float, default=0.5)\n","parser.add_argument('--save_best', type=str2bool, nargs='?', const=True, default='True')\n","parser.add_argument('--vocab_size', type=int, default=21128)\n","parser.add_argument('--max_seq_length', type=int, default=512)\n","\n","# data dir\n","parser.add_argument('--train_dir', type=str, default='/content/outputs/cmrc2018/data/train_features_albert.json')\n","parser.add_argument('--dev_dir1', type=str, default='/content/outputs/cmrc2018/data/dev_examples_albert.json')\n","parser.add_argument('--dev_dir2', type=str, default='/content/outputs/cmrc2018/data/dev_features_albert.json')\n","parser.add_argument('--train_file', type=str, default='/content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_train.json')\n","parser.add_argument('--dev_file', type=str, default='/content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_trial.json')\n","parser.add_argument('--vocab_file', type=str, default='')\n","parser.add_argument('--bert_config_file', type=str, default='')\n","parser.add_argument('--init_restore_dir', type=str, default='')\n","parser.add_argument('--checkpoint_dir', type=str, default='')\n","parser.add_argument('--setting_file', type=str, default='setting.txt')\n","parser.add_argument('--log_file', type=str, default='log.txt')\n","\n","# use some global vars for convenience\n","args = parser.parse_args(args=[])\n","\n","# 训练参数\n","args.model='albert_google'\n","args.float16=True\n","args.train_epochs=3\n","args.n_batch=32\n","args.lr=3e-5\n","args.seed=[123,456,789]\n","\n","# 设置模型相关参数，如果未设置的话\n","if args.model == 'albert_zh':\n","    from models.albert_zh_modeling import AlbertModelMRC, BertConfig as AlbertConfig\n","    #model_name = 'albert_base_zh_36k'\n","    model_name = 'albert_large_zh'\n","    model_path = '/content/drive/MyDrive/colab_data/models/%s/'%model_name\n","    args.vocab_file = args.vocab_file if args.vocab_file else model_path+'vocab.txt'\n","    args.bert_config_file = args.bert_config_file if args.bert_config_file else model_path+'albert_config_large.json'\n","    args.init_restore_dir = args.init_restore_dir if args.init_restore_dir else model_path+'albert_model.ckpt'\n","elif args.model in ['albert', 'albert_google']:\n","    if args.model == 'albert':  \n","        from models.albert_modeling import AlbertModelMRC, AlbertConfig\n","    else:\n","        from models.albert_google_modeling import AlbertModelMRC, AlbertConfig    \n","    model_name = 'albert_base'\n","    model_path = '/content/drive/MyDrive/colab_data/models/%s/'%model_name\n","    args.vocab_file = args.vocab_file if args.vocab_file else model_path+'vocab_chinese.txt'\n","    args.bert_config_file = args.bert_config_file if args.bert_config_file else model_path+'albert_config.json'\n","    args.init_restore_dir = args.init_restore_dir if args.init_restore_dir else model_path+'model.ckpt-best'\n","elif args.model == 'bert_google':\n","    from models.bert_google_modeling import BertModelMRC as AlbertModelMRC, BertConfig as AlbertConfig\n","    model_name = 'chinese_L-12_H-768_A-12'\n","    model_path = '/content/drive/MyDrive/colab_data/models/bert_chinese_L-12_H-768_A-12/%s/'%model_name\n","    args.vocab_file = args.vocab_file if args.vocab_file else model_path+'vocab.txt'\n","    args.bert_config_file = args.bert_config_file if args.bert_config_file else model_path+'bert_config.json'\n","    args.init_restore_dir = args.init_restore_dir if args.init_restore_dir else model_path+'bert_model.ckpt'\n","else:\n","    print(\"UNKNOWN model name: [\", args.model, \"]. Available mode: ablert, albert_zh, albert_google.\")\n","    sys.exit(0)\n","\n","args.checkpoint_dir = args.checkpoint_dir if args.checkpoint_dir else '/content/drive/MyDrive/colab_data/outputs/cmrc2018/%s'%model_name\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_ids\n","n_gpu = len(args.gpu_ids.split(','))\n","hvd = None\n","mpi_size = 1\n","mpi_rank = 0\n","training_hooks = None\n","print('GPU NUM', n_gpu)\n","\n","args.checkpoint_dir += ('/epoch{}_batch{}_lr{}_warmup{}_anslen{}_tf/'\n","                        .format(args.train_epochs, args.n_batch, args.lr, args.warmup_rate, args.max_ans_length))\n","args = utils.check_args(args, mpi_rank)\n","print_rank0('######## generating data ########')\n","\n","if mpi_rank == 0:\n","    tokenizer = BertTokenizer(vocab_file=args.vocab_file, do_lower_case=True)\n","    # assert args.vocab_size == len(tokenizer.vocab)\n","    if not os.path.exists(args.train_dir):\n","        json2features(args.train_file, [args.train_dir.replace('_features_', '_examples_'), args.train_dir], \n","            tokenizer, is_training=True, max_seq_length=args.max_seq_length)\n","\n","    if not os.path.exists(args.dev_dir1) or not os.path.exists(args.dev_dir2):\n","        json2features(args.dev_file, [args.dev_dir1, args.dev_dir2], \n","            tokenizer, is_training=False, max_seq_length=args.max_seq_length)\n","\n","train_data = json.load(open(args.train_dir, 'r'))\n","dev_examples = json.load(open(args.dev_dir1, 'r'))\n","dev_data = json.load(open(args.dev_dir2, 'r'))\n","\n","if mpi_rank == 0:\n","    if os.path.exists(args.log_file):\n","        os.remove(args.log_file)\n","\n","steps_per_epoch = len(train_data) // args.n_batch\n","eval_steps = int(steps_per_epoch * args.eval_epochs)\n","dev_steps_per_epoch = len(dev_data) // (args.n_batch * n_gpu)\n","if len(train_data) % args.n_batch != 0:\n","    steps_per_epoch += 1\n","if len(dev_data) % (args.n_batch * n_gpu) != 0:\n","    dev_steps_per_epoch += 1\n","total_steps = steps_per_epoch * args.train_epochs\n","warmup_iters = int(args.warmup_rate * total_steps)\n","\n","print_rank0('steps per epoch:', steps_per_epoch)\n","print_rank0('total steps:', total_steps)\n","print_rank0('warmup steps:', warmup_iters)\n","\n","F1s = []\n","EMs = []\n","best_f1_em = 0\n","with tf.device(\"/gpu:0\"):\n","    input_ids = tf.placeholder(tf.int32, shape=[None, args.max_seq_length], name='input_ids')\n","    input_masks = tf.placeholder(tf.float32, shape=[None, args.max_seq_length], name='input_masks')\n","    segment_ids = tf.placeholder(tf.int32, shape=[None, args.max_seq_length], name='segment_ids')\n","    start_positions = tf.placeholder(tf.int32, shape=[None, ], name='start_positions')\n","    end_positions = tf.placeholder(tf.int32, shape=[None, ], name='end_positions')\n","\n","# build the models for training and testing/validation\n","print_rank0('######## init model ########')\n","bert_config = AlbertConfig.from_json_file(args.bert_config_file)\n","train_model = AlbertModelMRC(config=bert_config,\n","                              is_training=True,\n","                              input_ids=input_ids,\n","                              input_mask=input_masks,\n","                              token_type_ids=segment_ids,\n","                              start_positions=start_positions,\n","                              end_positions=end_positions,\n","                              use_float16=args.float16)\n","\n","eval_model = AlbertModelMRC(config=bert_config,\n","                            is_training=False,\n","                            input_ids=input_ids,\n","                            input_mask=input_masks,\n","                            token_type_ids=segment_ids,\n","                            use_float16=args.float16)\n","\n","optimization = Optimizer(loss=train_model.train_loss,\n","                          init_lr=args.lr,\n","                          num_train_steps=total_steps,\n","                          num_warmup_steps=warmup_iters,\n","                          hvd=hvd,\n","                          use_fp16=args.float16,\n","                          loss_count=args.loss_count,\n","                          clip_norm=args.clip_norm)\n","\n","if mpi_rank == 0:\n","    saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=1)\n","else:\n","    saver = None\n","\n","for seed_ in args.seed:\n","    best_f1, best_em = 0, 0\n","    if mpi_rank == 0:\n","        with open(args.log_file, 'a') as aw:\n","            aw.write('===================================' +\n","                      'SEED:' + str(seed_)\n","                      + '===================================' + '\\n')\n","    print_rank0('SEED:', seed_)\n","    # random seed\n","    np.random.seed(seed_)\n","    random.seed(seed_)\n","    tf.set_random_seed(seed_)\n","\n","    train_gen = data_generator(train_data, args.n_batch, shuffle=True, drop_last=False)\n","    dev_gen = data_generator(dev_data, args.n_batch * n_gpu, shuffle=False, drop_last=False)\n","\n","    config = tf.ConfigProto()\n","    config.gpu_options.visible_device_list = str(mpi_rank)\n","    config.allow_soft_placement = True\n","    config.gpu_options.allow_growth = True\n","\n","    utils.show_all_variables(rank=mpi_rank)\n","    utils.init_from_checkpoint(args.init_restore_dir, rank=mpi_rank)\n","    RawResult = collections.namedtuple(\"RawResult\",\n","                                        [\"unique_id\", \"start_logits\", \"end_logits\"])\n","\n","    with tf.train.MonitoredTrainingSession(checkpoint_dir=None,\n","                                            hooks=training_hooks,\n","                                            config=config) as sess:\n","        old_global_steps = sess.run(optimization.global_step)\n","        for i in range(args.train_epochs):\n","            print_rank0('Starting epoch %d' % (i + 1))\n","            total_loss = 0\n","            iteration = 0\n","            with tqdm(total=steps_per_epoch, desc='Epoch %d' % (i + 1),\n","                      disable=False if mpi_rank == 0 else True) as pbar:\n","                while iteration < steps_per_epoch:\n","                    batch_data = next(train_gen)\n","                    feed_data = {input_ids: batch_data['input_ids'],\n","                                  input_masks: batch_data['input_mask'],\n","                                  segment_ids: batch_data['segment_ids'],\n","                                  start_positions: batch_data['start_position'],\n","                                  end_positions: batch_data['end_position']}\n","                    loss, _, global_steps = sess.run(\n","                        [train_model.train_loss, optimization.train_op, optimization.global_step],\n","                        feed_dict=feed_data)\n","                    if global_steps > old_global_steps:\n","                        old_global_steps = global_steps\n","                        total_loss += loss\n","                        pbar.set_postfix({'loss': '{0:1.5f}'.format(total_loss / (iteration + 1e-5))})\n","                        pbar.update(1)\n","                        iteration += 1\n","                    else:\n","                        print_rank0('NAN loss in', iteration, ', Loss scale reduced', )\n","\n","                    if global_steps % eval_steps == 0 and global_steps > 1:\n","                        print_rank0('Evaluating...')\n","                        all_results = []\n","                        for i_step in tqdm(range(dev_steps_per_epoch),\n","                                            disable=False if mpi_rank == 0 else True):\n","                            batch_data = next(dev_gen)\n","                            feed_data = {input_ids: batch_data['input_ids'],\n","                                          input_masks: batch_data['input_mask'],\n","                                          segment_ids: batch_data['segment_ids']}\n","                            batch_start_logits, batch_end_logits = sess.run(\n","                                [eval_model.start_logits, eval_model.end_logits],\n","                                feed_dict=feed_data)\n","                            for j in range(len(batch_data['unique_id'])):\n","                                start_logits = batch_start_logits[j]\n","                                end_logits = batch_end_logits[j]\n","                                unique_id = batch_data['unique_id'][j]\n","                                all_results.append(RawResult(unique_id=unique_id,\n","                                                              start_logits=start_logits,\n","                                                              end_logits=end_logits))\n","                        if mpi_rank == 0:\n","                            output_prediction_file = os.path.join(args.checkpoint_dir,\n","                                                                  'prediction_epoch' + str(i) + '.json')\n","                            output_nbest_file = os.path.join(args.checkpoint_dir, 'nbest_epoch' + str(i) + '.json')\n","\n","                            write_predictions(dev_examples, dev_data, all_results,\n","                                              n_best_size=args.n_best, max_answer_length=args.max_ans_length,\n","                                              do_lower_case=True, output_prediction_file=output_prediction_file,\n","                                              output_nbest_file=output_nbest_file)\n","                            tmp_result = get_eval(args.dev_file, output_prediction_file)\n","                            tmp_result['STEP'] = global_steps\n","                            print_rank0(tmp_result)\n","                            with open(args.log_file, 'a') as aw:\n","                                aw.write(json.dumps(str(tmp_result)) + '\\n')\n","\n","                            if float(tmp_result['F1']) > best_f1:\n","                                best_f1 = float(tmp_result['F1'])\n","                            if float(tmp_result['EM']) > best_em:\n","                                best_em = float(tmp_result['EM'])\n","\n","                            if float(tmp_result['F1']) + float(tmp_result['EM']) > best_f1_em:\n","                                best_f1_em = float(tmp_result['F1']) + float(tmp_result['EM'])\n","                                scores = {'F1': float(tmp_result['F1']), 'EM': float(tmp_result['EM'])}\n","                                save_prex = \"checkpoint_score\"\n","                                for k in scores:\n","                                    save_prex += ('_' + k + '-' + str(scores[k])[:6])\n","                                save_prex += '.ckpt'\n","                                saver.save(get_session(sess),\n","                                            save_path=os.path.join(args.checkpoint_dir, save_prex))\n","\n","    F1s.append(best_f1)\n","    EMs.append(best_em)\n","\n","if mpi_rank == 0:\n","    print('Mean F1:', np.mean(F1s), 'Mean EM:', np.mean(EMs))\n","    print('Best F1:', np.max(F1s), 'Best EM:', np.max(EMs))\n","    with open(args.log_file, 'a') as aw:\n","        aw.write('Mean(Best) F1:{}({})\\n'.format(np.mean(F1s), np.max(F1s)))\n","        aw.write('Mean(Best) EM:{}({})\\n'.format(np.mean(EMs), np.max(EMs)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU NUM 1\n","------------ Options -------------\n","model: albert_google\n","gpu_ids: 0\n","train_epochs: 3\n","n_batch: 32\n","lr: 3e-05\n","dropout: 0.1\n","clip_norm: 1.0\n","warmup_rate: 0.1\n","loss_count: 1000\n","seed: [123, 456, 789]\n","float16: True\n","max_ans_length: 50\n","log_interval: 30\n","n_best: 20\n","eval_epochs: 0.5\n","save_best: True\n","vocab_size: 21128\n","max_seq_length: 512\n","train_dir: /content/outputs/cmrc2018/data/train_features_albert.json\n","dev_dir1: /content/outputs/cmrc2018/data/dev_examples_albert.json\n","dev_dir2: /content/outputs/cmrc2018/data/dev_features_albert.json\n","train_file: /content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_train.json\n","dev_file: /content/drive/MyDrive/colab_data/data/cmrc2018/cmrc2018_trial.json\n","vocab_file: /content/drive/MyDrive/colab_data/models/albert_base/vocab_chinese.txt\n","bert_config_file: /content/drive/MyDrive/colab_data/models/albert_base/albert_config.json\n","init_restore_dir: /content/drive/MyDrive/colab_data/models/albert_base/model.ckpt-best\n","checkpoint_dir: /content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch3_batch32_lr3e-05_warmup0.1_anslen50_tf/\n","setting_file: /content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch3_batch32_lr3e-05_warmup0.1_anslen50_tf/setting.txt\n","log_file: /content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch3_batch32_lr3e-05_warmup0.1_anslen50_tf/log.txt\n","------------ End -------------\n","######## generating data ########\n"],"name":"stdout"},{"output_type":"stream","text":[" 17%|█▋        | 555/3251 [00:00<00:01, 1364.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["6061的密度为2.70g/cm³6061 V.S 6061的密度为2.70g/cm³\n"],"name":"stdout"},{"output_type":"stream","text":[" 29%|██▉       | 947/3251 [00:00<00:01, 1329.29it/s]"],"name":"stderr"},{"output_type":"stream","text":[".CPB根据宪法设立但独立于泰国政府.普美蓬国王积极参与了该局的管理. V.S CPB根据宪法设立但独立于泰国政府.普美蓬国王积极参与了该局的管理.\n","如果  是代数数，在有理数  内是线性独立的，那么formula_1在  内是代数独立的； V.S 如果是代数数，在有理数内是线性独立的，那么formula_1在内是代数独立的；\n","如果  是不同的代数数，那么指数  在代数数范围内是线性独立的。 V.S 如果是不同的代数数，那么指数在代数数范围内是线性独立的。\n"],"name":"stdout"},{"output_type":"stream","text":[" 42%|████▏     | 1351/3251 [00:01<00:01, 1344.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["'pointviewdimension' V.S pointviewdimension'\n","BeOS.CodeWarrior支援Pascal，ObjectPascal，Objective-C，以及Javacompilers，可以开发MacAP与Macdriver V.S CodeWarrior支援Pascal，ObjectPascal，Objective-C，以及Javacompilers，可以开发MacAP与Macdriver\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|████▉     | 1613/3251 [00:01<00:01, 1303.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["任何关于  的一阶命题如果成立，则对  也成立。 V.S 任何关于的一阶命题如果成立，则对也成立。\n","每  长度的波长数量（即每单位长度的波长数量乘以 ）。 V.S 每长度的波长数量（即每单位长度的波长数量乘以）。\n"],"name":"stdout"},{"output_type":"stream","text":[" 71%|███████   | 2294/3251 [00:01<00:00, 1325.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["在\"F\"中(考虑为整数带有0 ≤ \"c\" < \"p\")给予\"V\"一个自然的\"F\"-模结构。 V.S 在\"F\"中(考虑为整数带有0≤\"c\"<\"p\")给予\"V\"一个自然的\"F\"-模结构。\n","Godknows... V.S Godknows\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3251/3251 [00:02<00:00, 1345.22it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["examples num: 13361\n","mis_match: 10\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 13361/13361 [01:16<00:00, 174.41it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["features num: 22616\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIBCICZFTxGL","outputId":"3a82fdb1-71e9-4944-9a15-f35e5e6d5243"},"source":["#!tar cvfJ /content/drive/MyDrive/colab_data/echo4.xv /content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tar: Removing leading `/' from member names\n","/content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf/\n","/content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf/setting.txt\n","/content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf/log.txt\n","/content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf/checkpoint\n","/content/drive/MyDrive/colab_data/outputs/cmrc2018/albert_base/epoch4_batch32_lr3e-05_warmup0.1_anslen50_tf/checkpoint_score_F1-72.748_EM-36.727.ckpt.data-00000-of-00001\n"],"name":"stdout"}]}]}